@phdthesis{Asano2015,
  title        = {Individual Colorimetric Observers for Personalized
    Color Imaging},
  author       = {Asano, Yuta},
  year         = 2015,
  school       = {R.I.T.},
}
@misc{Brendel2020,
  title        = {Measured Commercial LED Spectra},
  author       = {Brendel, Harald},
  year         = 2020,
  month        = apr,
  url          = {https://haraldbrendel.com/files/led_spd_350_700.csv},
  urldate      = {2020-09-26},
}
@article{Breneman1987b,
  title        = {Corresponding chromaticities for different states of
    adaptation to complex visual fields},
  author       = {Breneman, Edwin J.},
  year         = 1987,
  month        = jun,
  volume       = 4,
  pages        = 1115,
  issn         = {1084-7529},
  doi          = {10.1364/JOSAA.4.001115},
  abstract     = {While each of his or her two eyes was independently
    adapted to a different illuminant in viewing a complex visual
    field, each of a number of observers matched a series of test
    colors seen by one eye with a juxtaposed variable stimulus seen by
    the other eye. The 2 degrees test and matching stimuli were
    located centrally in the complex adapting field, which subtended
    an angle of 31 degrees X 24 degrees. In making the matches, the
    observer viewed the test and matching stimuli for a series of
    brief intervals (approximately 1 sec) while viewing the complex
    adapting field with normal eye movements. Nine experiments were
    performed with different pairs of illuminants and different
    illuminances ranging from that of an average living room to that
    of a scene illuminated with hazy sunlight. In three other
    experiments each of the observer's two eyes was adapted to a
    different illuminance of D55. The amount of adaptation was more
    nearly complete at high levels of illuminance than at low levels,
    and the proportional amount of adaptation was less for the "blue"
    receptors. When adaptation coefficients were determined from the
    actual adaptation differences (e.g., from corresponding
    tristimulus values for matching neutrals) rather than from the
    adapting illuminants, a linear von Kries transformation based on
    experimentally determined visual primaries gave corresponding
    chromaticities that were in good agreement with the results
    obtained in each of the chromatic-adaptation experiments, except
    at the lowest illuminances. The results of the experiments in
    which each eye was adapted to different levels of the same
    illuminant indicated again that adaptation to the different levels
    was incomplete, the proportional amount of adaptation being less
    at low illuminances and for the "blue" receptors. This caused a
    change in chromatic adaptation with the level of illuminance even
    when the chromaticities of the adapting lights were equal. The
    results of these experiments also indicated that higher purities
    are needed in order to produce the same absolute color appearances
    at low levels of illuminance.},
  journal      = {Journal of the Optical Society of America A},
  number       = 6,
  pmid         = 3598755,
}
@misc{Dyer2017,
  title        = {RAW to ACES Utility Data},
  author       = {Dyer, Scott and Forsythe, Alexander and Irons,
    Jonathon and Mansencal, Thomas and Zhu, Miaoqi},
  year         = 2017,
}
@inproceedings{Ebner1998,
  title        = {Finding constant hue surfaces in color space},
  booktitle    = {Proc. SPIE 3300, Color Imaging: Device-Independent
    Color, Color Hardcopy, and Graphic Arts III, (2 January 1998)},
  author       = {Ebner, Fritz and Fairchild, Mark D.},
  editor       = {Beretta, Giordano B. and Eschbach, Reiner},
  year         = 1998,
  month        = jan,
  pages        = {107--117},
  doi          = {10.1117/12.298269},
}
@misc{Haanpalo,
  title        = {Munsell Colors Glossy (Spectrofotometer Measured)},
  author       = {Haanpalo, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269916},
}
@misc{Haanpaloa,
  title        = {Paper Spectra},
  author       = {Haanpalo, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269922},
}
@misc{Hauta-Kasari,
  title        = {Munsell Colors Matt (Spectrofotometer Measured)},
  author       = {{Hauta-Kasari}, Markku and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269912},
}
@misc{Hauta-Kasaria,
  title        = {Munsell Colors Matt (AOTF Measured)},
  author       = {{Hauta-Kasari}, Markku and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269914},
}
@misc{Hiltunen,
  title        = {Lumber Spectra},
  author       = {Hiltunen, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269924},
}
@article{Hung1995,
  title        = {Determination of constant Hue Loci for a CRT gamut
    and their predictions using color appearance spaces},
  author       = {Hung, Po-Chieh and Berns, Roy S.},
  year         = 1995,
  month        = oct,
  volume       = 20,
  pages        = {285--295},
  issn         = 03612317,
  doi          = {10.1002/col.5080200506},
  journal      = {Color Research \& Application},
  keywords     = {color appearance spaces,experiments to evaluate
    color space hue linearity,perceived hue},
  number       = 5,
}
@article{Jakob2019,
  ids          = {Jakob},
  title        = {A Low-Dimensional Function Space for Efficient
    Spectral Upsampling},
  author       = {Jakob, Wenzel and Hanika, Johannes},
  year         = 2019,
  month        = may,
  volume       = 38,
  pages        = {147--155},
  issn         = {0167-7055, 1467-8659},
  doi          = {10.1111/cgf.13626},
  journal      = {Computer Graphics Forum},
  language     = {en},
  number       = 2,
}
@inproceedings{Jiang2013,
  title        = {What is the space of spectral sensitivity functions
    for digital color cameras?},
  booktitle    = {2013 IEEE Workshop on Applications of Computer
    Vision (WACV)},
  author       = {Jiang, Jun and Liu, Dengyu and Gu, Jinwei and
    Susstrunk, Sabine},
  year         = 2013,
  month        = jan,
  pages        = {168--179},
  publisher    = {IEEE},
  issn         = 21583978,
  doi          = {10.1109/WACV.2013.6475015},
  abstract     = {Camera spectral sensitivity functions relate scene
    radiance with captured RGB triplets. They are important for many
    computer vision tasks that use color information, such as
    multispectral imaging, color rendering, and color constancy. In
    this paper, we aim to explore the space of spectral sensitivity
    functions for digital color cameras. After collecting a database
    of 28 cameras covering a variety of types, we find this space
    convex and two-dimensional. Based on this statistical model, we
    propose two methods to recover camera spectral sensitivities using
    regular reflective color targets (e.g., color checker) from a
    single image with and without knowing the illumination. We show
    the proposed model is more accurate and robust for estimating
    camera spectral sensitivities than other basis functions. We also
    show two applications for the recovery of camera spectral
    sensitivities - simulation of color rendering for cameras and
    computational color constancy.},
  isbn         = {978-1-4673-5054-9},
}
@misc{Labsphere2019,
  title        = {Labsphere SRS-99-020},
  author       = {{Labsphere}},
  year         = 2019,
  doi          = {10.5281/zenodo.3245875},
}
@article{Luo1991,
  title        = {Quantifying colour appearance. Part I. Lutchi colour
    appearance data},
  author       = {Luo, M. Ronnier and Clarke, Anthony A. and Rhodes,
    Peter A. and Schappo, Andr{\'e} and Scrivener, Stephen A. R. and
    Tait, Chris J.},
  year         = 1991,
  month        = jun,
  volume       = 16,
  pages        = {166--180},
  issn         = 03612317,
  doi          = {10.1002/col.5080160307},
  abstract     = {The experimental data from this study supplements
    the LUTCHI Colour Appearance Data as described in Part I of this
    paper. Two further experiments were carried out: one was to check
    conflicting results found previously, and another was to extend
    the range of luminance conditions used earlier. In addition, a
    brightness attribute was added to the original lightness,
    colourfulness, and hue scales for colour assessment. Experiment I
    results verified the uncertainties found previously in the
    comparison between luminous and nonluminous colours, and between
    the grey background results with and without a white border.
    Experiment II results revealed the changes in four perceived
    attributes under six quite different adapting luminances. The
    results were then used to test five uniform colour spaces and
    colour-appearance models used in Part II of this paper. Hunt's 91
    model gave more accurate predictions of the experimental visual
    results, in comparison with the other spaces and models. Its
    predictive error for all attributes studied is within the accuracy
    of the typical observer.},
  journal      = {Color Research \& Application},
  number       = 3,
}
@article{Luo1991a,
  title        = {Quantifying colour appearance. Part II. Testing
    colour models performance using lutchi colour appearance data},
  author       = {Luo, M. Ronnier and Clarke, Anthony A. and Rhodes,
    Peter A. and Schappo, Andr{\'e} and Scrivener, Stephen A.R. and
    Tait, Chris J.},
  year         = 1991,
  volume       = 16,
  pages        = {181--197},
  issn         = 15206378,
  doi          = {10.1002/col.5080160308},
  abstract     = {The acquisition of the LUTCHI Colour Appearance Data
    has been described in Part I of this article. Having obtained the
    data, they were used to test the accuracy of prediction for
    various colour spaces and models. The results clearly indicate
    that Hunt's 91 model gives the best fit to the visual results of
    all the models studied. Hunt's 91 has been further refined to
    improve the fit to the colourfulness results, and this refined
    model has been designated Hunt-ACAM (ACAM being the Alvey Colour
    Appearance Model). The error of prediction from Hunt-ACAM is close
    to the typical error that is seen to occur between individuals'
    results and the mean visual results. This performance is
    considered to be very satisfactory, and the model is therefore
    believed to provide a reasonably accurate way of evaluating colour
    fidelity for various colour reproduction systems. Various
    chromatic-adaptation transformations were also compared with three
    sets of corresponding chromaticities derived from the results of
    experiments conducted under four conditions of chromatic
    adaptation. The results are in reasonable agreement with those
    obtained by Helson et al. [Illum. Eng. 47, 221-233 (1952)] and Lam
    and Rigg [Ph.D. thesis, University of Bradford (1985)]. All
    results indicate that the Bradford and Hunt-ACAM transformations
    perform the best and the second best, respectively, of all the
    selected formulae. The current CIE recommendation does not perform
    as well as expected.},
  journal      = {Color Research \& Application},
  number       = 3,
}
@article{Luo1993,
  title        = {Quantifying colour appearance. part III.
    Supplementary LUTCHI colour appearance data},
  author       = {Luo, M. Ronnier and Gao, X. Wang and Rhodes, Peter
    A. and Xin, H. John and Clarke, Anthony A. and Scrivener, Stephen
    A.R.},
  year         = 1993,
  volume       = 18,
  pages        = {98--113},
  issn         = 15206378,
  doi          = {10.1002/col.5080180207},
  abstract     = {The experimental data from this study supplements
    the LUTCHI Colour Appearance Data as described in Part I of this
    paper. Two further experiments were carried out: one was to check
    conflicting results found previously, and another was to extend
    the range of luminance conditions used earlier. In addition, a
    brightness attribute was added to the original lightness,
    colourfulness, and hue scales for colour assessment. Experiment I
    results verified the uncertainties found previously in the
    comparison between luminous and nonluminous colours, and between
    the grey background results with and without a white border.
    Experiment II results revealed the changes in four perceived
    attributes under six quite different adapting luminances. The
    results were then used to test five uniform colour spaces and
    colour-appearance models used in Part II of this paper. Hunt's 91
    model gave more accurate predictions of the experimental visual
    results, in comparison with the other spaces and models. Its
    predictive error for all attributes studied is within the accuracy
    of the typical observer. Copyright \textcopyright{} 1993 Wiley
    Periodicals, Inc., A Wiley Company},
  journal      = {Color Research \& Application},
  number       = 2,
}
@misc{Luo1997,
  title        = {Using the LUTCHI Colour Appearance Data},
  author       = {Luo, M Ronnier and Rhodes, Peter A.},
  year         = 1997,
  url          = {https://web.archive.org/web/20040212195937/http://colour.derby.ac.uk:80/colour/info/lutchi/},
  urldate      = {2019-09-10},
}
@article{Luo1999,
  title        = {Corresponding-colour datasets},
  author       = {Luo, M. Ronnier and Rhodes, Peter A.},
  year         = 1999,
  month        = aug,
  volume       = 24,
  pages        = {295--296},
  issn         = {0361-2317},
  doi          = {10.1002/(SICI)1520-6378(199908)24:4<295::AID-COL10>3.0.CO;2-K},
  abstract     = {Predicting the binding mode of flexible polypeptides
    to proteins is an important task that falls outside the domain of
    applicability of most small molecule and protein-protein docking
    tools. Here, we test the small molecule flexible ligand docking
    program Glide on a set of 19 non-{$\alpha$}-helical peptides and
    systematically improve pose prediction accuracy by enhancing Glide
    sampling for flexible polypeptides. In addition, scoring of the
    poses was improved by post-processing with physics-based implicit
    solvent MM- GBSA calculations. Using the best RMSD among the top
    10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0
    \AA{} for the interface backbone atoms) increased from 21\% with
    default Glide SP settings to 58\% with the enhanced peptide
    sampling and scoring protocol in the case of redocking to the
    native protein structure. This approaches the accuracy of the
    recently developed Rosetta FlexPepDock method (63\% success for
    these 19 peptides) while being over 100 times faster.
    Cross-docking was performed for a subset of cases where an unbound
    receptor structure was available, and in that case, 40\% of
    peptides were docked successfully. We analyze the results and find
    that the optimized polypeptide protocol is most accurate for
    extended peptides of limited size and number of formal charges,
    defining a domain of applicability for this approach.},
  journal      = {Color Research \& Application},
  number       = 4,
}
@misc{Marszalec,
  title        = {Agfa IT8.7/2 Set},
  author       = {Marszalec, Elzbieta and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269926},
}
@article{McCann1976,
  title        = {Quantitative studies in retinex theory a comparison
    between theoretical predictions and observer responses to the
    "color mondrian" experiments},
  author       = {McCann, John J. and McKee, Suzanne P. and Taylor,
    Thomas H},
  year         = 1976,
  month        = jan,
  volume       = 16,
  pages        = {445-IN3},
  issn         = 00426989,
  doi          = {10.1016/0042-6989(76)90020-1},
  journal      = {Vision Research},
  number       = 5,
}
@misc{OpenpyxlDevelopers2019,
  title        = {openpyxl},
  author       = {{Openpyxl Developers}},
  year         = 2019,
  url          = {https://bitbucket.org/openpyxl/openpyxl/},
}
@misc{Orava,
  title        = {Munsell Colors Glossy (All) (Spectrofotometer
    Measured)},
  author       = {Orava, Joni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269918},
}
@misc{Silvennoinen,
  title        = {Forest Colors},
  author       = {Silvennoinen, Raimo and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269920},
}
@misc{X-Rite2016,
  title        = {New color specifications for ColorChecker SG and
    Classic Charts},
  author       = {{X-Rite}},
  year         = 2016,
  url          = {http://xritephoto.com/ph_product_overview.aspx?ID=938\&Action=Support\&SupportID=5884\#},
  urldate      = {2018-10-29},
}
@misc{Zhao2009,
  title        = {Estimating basis functions for spectral sensitivity
    of digital cameras},
  author       = {Zhao, Hongxun and Kawakami, Rei and Tan, Robby T and
    Ikeuchi, Katsushi},
  year         = 2009,
  abstract     = {Spectral sensitivity of digital cameras plays an
    important role for many computer vision applications. However,
    less attention has been drawn on estimating the spectral
    sensitivity of commercial cameras, and there is neither
    comprehensive analysis of those spectral characteristics. This
    paper investigates the characteristics by extracting the basis
    functions of them by using SVD (Singular Value Decomposition); we
    have collected data from the literature but also by measuring the
    sensitivity of different cameras. This paper compares the
    extracted basis functions with different mathematical basis
    functions and obtains the optimum set of basis functions. The
    extracted basis functions can be used to estimate the unknown
    spectral sensitivity of an arbitrary camera.},
  keywords     = {⛔ No DOI found},
  language     = {en},
}
